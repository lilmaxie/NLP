{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1607e4",
   "metadata": {},
   "source": [
    "#### STEMMING ####\n",
    "Stemming is the process of reducing a word to its base or root form. For example, the words \"running\", \"runner\", and \"ran\" can all be reduced to the root word \"run\". This is useful in text analysis as it helps to group similar words together, reducing the complexity of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015bbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\", \"eats\", \"ate\", \"eaten\", \"eat\", \"eater\", \"eaters\", \"eating\", \"writing\", \"writes\", \"wrote\", \"written\", \"write\", \"writer\", \"writers\", \"programming\", \"programs\", \"programmed\", \"programmer\", \"programmers\", \"programming\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea07677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aba5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06cfddb",
   "metadata": {},
   "source": [
    "The disadvantage of stemming is that it can sometimes produce non-words or words that are not meaningful. For example, the word \"running\" might be reduced to \"run\", but it could also be reduced to \"runn\" which is not a valid word. This can lead to confusion and misinterpretation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582bc264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eats ---> eat\n",
      "ate ---> ate\n",
      "eaten ---> eaten\n",
      "eat ---> eat\n",
      "eater ---> eater\n",
      "eaters ---> eater\n",
      "eating ---> eat\n",
      "writing ---> write\n",
      "writes ---> write\n",
      "wrote ---> wrote\n",
      "written ---> written\n",
      "write ---> write\n",
      "writer ---> writer\n",
      "writers ---> writer\n",
      "programming ---> program\n",
      "programs ---> program\n",
      "programmed ---> program\n",
      "programmer ---> programm\n",
      "programmers ---> programm\n",
      "programming ---> program\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \" ---> \"+ stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9dcb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some words that don't give a good stem\n",
    "stemming.stem(\"congratulations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba725d",
   "metadata": {},
   "source": [
    "#### RegexpStemmer class ####\n",
    "NLTK has RegexpSteemer class with the help of which we can easily implement Regular Expression based stemming. The RegexpStemmer class allows us to define our own stemming rules using regular expressions. This gives us more control over the stemming process and allows us to create custom stemming rules that are specific to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3cb3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RegexpStemmer: 'ing$|s$|es$|ed$'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "reg_stemmer = RegexpStemmer('ing$|s$|es$|ed$', min=4)\n",
    "reg_stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8820f1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runn'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99084336",
   "metadata": {},
   "source": [
    "#### SNOWBALL STEMMER ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28c5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f8d5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eats ---> eat\n",
      "ate ---> ate\n",
      "eaten ---> eaten\n",
      "eat ---> eat\n",
      "eater ---> eater\n",
      "eaters ---> eater\n",
      "eating ---> eat\n",
      "writing ---> write\n",
      "writes ---> write\n",
      "wrote ---> wrote\n",
      "written ---> written\n",
      "write ---> write\n",
      "writer ---> writer\n",
      "writers ---> writer\n",
      "programming ---> program\n",
      "programs ---> program\n",
      "programmed ---> program\n",
      "programmer ---> programm\n",
      "programmers ---> programm\n",
      "programming ---> program\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \" ---> \"+ snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d3865",
   "metadata": {},
   "source": [
    "#### COMPARE BETWEEN POTERSTEMMER AND SNOWBALL STEMMER ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0085d919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'supportingli')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"), stemming.stem(\"supportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fe0d9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'support')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem(\"fairly\"), snowball_stemmer.stem(\"supportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b5b95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
